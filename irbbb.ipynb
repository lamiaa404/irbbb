{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "742adba1-54cd-47b6-b445-d82cb2250c64",
   "metadata": {},
   "source": [
    "# Informational Retrieval Project - IR Anthology\n",
    "\n",
    "In this notebook you will write your code, producing the required output for each Milestone.\n",
    "\n",
    "Your notebook must contain 3 types of cells:\n",
    "\n",
    "- (1) Code cells: Cells that contain code snippets, capturing one cohesive fragment of your code.\n",
    "- (2) Corresponding explanation cells: Each code cell must be followed by a text cell containing the **english** explanation of what the corresponding code cell does and what it's purpose is\n",
    "- (3) One reflection cell: One cell at the bottom of the notebook that contains your individual reflection on your process working on this milestones in **english**. It could contain technical problems and how you overcame them, it could contain social problems and how you deal with them (group work is hard!), it could contain explanations of prior skills or knowledge that made certain parts of the task easier for you, etc... (those are just suggestions. Your individual reflections will of course contain different/additional aspects)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51e766c4",
   "metadata": {},
   "source": [
    "### Step 1: the document collection in .jsonl-format, a form consistent with ir_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa832d-c0ed-41dd-b4a9-68580c1ae974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Processing\n",
    "\n",
    "import json\n",
    "\n",
    "# 1. Open and read the jsonl file\n",
    "with open(\"/Users/lh/Documents/Projects/ir/data/raw data/ir-anthology-07-11-2021-ss23.jsonl\", 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 2. Extract the id key and create a new jsonl file\n",
    "with open(\"ir_anthology.jsonl\", 'w') as f:\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        doc_id = data['id']\n",
    "        text = {k: v for k, v in data.items() if k != 'id'}\n",
    "        new_data = {'doc_id': doc_id, 'text': text}\n",
    "        json.dump(new_data, f)\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0440f20e-3c64-44c3-8537-f5065f792f8a",
   "metadata": {},
   "source": [
    "### Explanation for the raw data processing code:\n",
    "\n",
    "1.The code imports the json module, which provides a way to work with JSON data in Python. It then opens a JSON Lines file named \"ir-anthology-07-11-2021-ss23.jsonl\" in read mode and reads all its lines into a list named lines.\n",
    "2.The code creates a new JSON Lines file named \"ir_anthology.jsonl\" in write mode and iterates over each line in lines. For each line, it loads the JSON string into a Python dictionary named data using the json.loads() method. It then extracts the value of the \"id\" key and stores it in a variable named doc_id.\n",
    "Next, the code creates a new dictionary named text that contains all the key-value pairs from the original data dictionary except for the \"id\" key. This is done using a dictionary comprehension that iterates over the items in data and only keeps those that have a key different from \"id\".\n",
    "Finally, the code creates a new dictionary named new_data that contains the \"doc_id\" and \"text\" keys with their corresponding values. It then writes this dictionary as a JSON string to the new file using the json.dump() method, followed by a newline character (\\n) to separate each object in the JSON Lines file.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "095961a5",
   "metadata": {},
   "source": [
    "###Step 2: your custom topics for your dataset in TREC XML-format:\n",
    "\n",
    "We chose the topic using text analysis and the content from the lectures that we had so far. We perfomed a text analysis using python and we used chatnoir to check the topics that we came up with. For example we thought of the topic using neural networks in informational retrieval as we found abstracts in the datasets on the topic and then we searched chatnoir using the words \"neural networks in informational retrieval\". "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1f614e3-7fe6-4d84-9f25-47fc9b341ccb",
   "metadata": {},
   "source": [
    "### Reflection Cell\n",
    "\n",
    "Working on the first milestone has been very difficult. First of all our lab sessions were not very helpful because we were told to do the tutorial without further explanations and even after much research and finishing the tutorial we could not understand the assignment we were given. The tutorials themselves were lacking more detailed explanations so we had to ask and research a lot. Additionally a more detailed task would have also been very useful although the Q&A session did clear some missunderstandings but it wasn't enough. The template we were offered did give us the idea how to wirte the python code for example but even with all the tutorials we could not find out why the hashcodes didn't match. Without the help of another tutor we would have never found a solution. It would have been better to adjust the template to our task. As it was tailored to the example there were lines such as \"from ir_datasets.util.download import RequestsDownload\" which were unnecessary for us. Our teamwork has played a very important role in getting through the first milestone as we motivated each other to push through even without much prior knowledge to python, docker and command lines. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
